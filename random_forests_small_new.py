from pyspark.sql import SparkSession
from pyspark.ml.linalg import SparseVector, VectorUDT, Vectors
from pyspark.sql.types import *
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.feature import ChiSqSelector
from pyspark.ml.feature import PCA
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

#initialize spark session
spark = SparkSession\
        .builder\
        .appName("Test")\
        .config('spark.sql.warehouse.dir', 'file:///C:/')\
        .getOrCreate()
sc = spark.sparkContext

#load data
train_bytes = spark.read.load("./data/train_small_bytes.parquet")
test_bytes = spark.read.load("./data/test_small_bytes.parquet")
train_asm = spark.read.load("./data/train_small_asm.parquet")
test_asm = spark.read.load("./data/test_small_asm.parquet")

#chisqr feature selector
selector1 = ChiSqSelector(numTopFeatures=150, outputCol="selectedFeatures")
selectormodel1 = selector1.fit(train_bytes)
train_bytes = selectormodel1.transform(train_bytes)
test_bytes = selectormodel1.transform(test_bytes)

selector2 = ChiSqSelector(numTopFeatures=150, outputCol="selectedFeatures")
selectormodel2 = selector2.fit(train_asm)
train_asm = selectormodel2.transform(train_asm)
test_asm = selectormodel2.transform(test_asm)
'''
#pca
pca1 = PCA(k=100, inputCol="features", outputCol="selectedFeatures")
model1 = pca1.fit(train_bytes)
train_bytes = model1.transform(train_bytes)
test_bytes = model1.transform(test_bytes)

pca2 = PCA(k=100, inputCol="features", outputCol="selectedFeatures")
model2 = pca2.fit(train_asm)
train_asm = model2.transform(train_asm)
test_asm = model2.transform(test_asm)
'''
#to rdd
train_bytes = train_bytes.select('hash','selectedFeatures','label').rdd.map(lambda (hash,feats,label):(hash,(feats,label)))
test_bytes = test_bytes.select('hash','selectedFeatures','label').rdd.map(lambda (hash,feats,label):(hash,(feats,label)))
train_asm = train_asm.select('hash','selectedFeatures','label').rdd.map(lambda (hash,feats,label):(hash,(feats,label)))
test_asm = test_asm.select('hash','selectedFeatures','label').rdd.map(lambda (hash,feats,label):(hash,(feats,label)))

#merge bytes and asm data
train = train_bytes.join(train_asm).map(lambda (hash,((bytes,label),(asm,label2))):(bytes,asm,label))
test = test_bytes.join(test_asm).map(lambda (hash,((bytes,label),(asm,label2))):(bytes,asm,label))
schema = StructType([StructField('bytes',VectorUDT(),True),StructField('asm',VectorUDT(),True),StructField('label',StringType(),True)])
train = train.toDF(schema)
train = train.withColumn('label',train.label.cast(DoubleType()))
test = test.toDF(schema)
test = test.withColumn('label',test.label.cast(DoubleType()))
            
#merge bytes and asm features
assembler = VectorAssembler(inputCols=["bytes", "asm"],outputCol="features")
train = assembler.transform(train)
test = assembler.transform(test)

#rf classifier
rf = RandomForestClassifier(numTrees=100,maxDepth=8,maxBins=48,maxMemoryInMB=512,seed=1)
model = rf.fit(train)
result = model.transform(test)

print result.show()

#get accuracy
predictionAndLabels = result.select("prediction", "label")
evaluator = MulticlassClassificationEvaluator(metricName="accuracy")
print "Accuracy: " + str(evaluator.evaluate(predictionAndLabels))
from pyspark.sql import SparkSession
from pyspark.mllib.linalg import SparseVector, VectorUDT, Vectors
from pyspark.sql.types import *
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
import sys

if __name__ == '__main__':

#-------------------------------------------------------------------------------
# Initialize Spark
#-------------------------------------------------------------------------------
    #initialize spark session
    spark = SparkSession\
            .builder\
            .appName("Test")\
            .getOrCreate()
    sc = spark.sparkContext

#-------------------------------------------------------------------------------
# Read the training data and build the model
#-------------------------------------------------------------------------------
    #load data
    ytest = sc.textFile('./data/y_test_small.txt').zipWithIndex().map(lambda x:(x[1],x[0]))
    mytest = sc.textFile('/Users/admin/Documents/pythonworkspace/data-science-practicum/project-2/eatingnails-project2/l1output.txt').zipWithIndex().map(lambda x:(x[1],x[0]))

    joined = ytest.join(mytest)

    #print joined.take(50)
    
    matched = joined.filter(lambda (x,(y1,y2)):y1==y2).count()
    unmatched = joined.filter(lambda (x,(y1,y2)):y1!=y2).count()

    print "matched"
    print matched

    print "unmatched"
    print unmatched
    
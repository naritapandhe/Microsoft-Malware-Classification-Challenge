from pyspark.sql import SparkSession
from pyspark.mllib.linalg import SparseVector, VectorUDT, Vectors
from pyspark.sql.types import *
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
import sys

if __name__ == '__main__':

#-------------------------------------------------------------------------------
# Initialize Spark
#-------------------------------------------------------------------------------
    #initialize spark session
    spark = SparkSession\
            .builder\
            .appName("Test")\
            .getOrCreate()
    sc = spark.sparkContext

#-------------------------------------------------------------------------------
# Read the training data and build the model
#-------------------------------------------------------------------------------
    #load data
    ytest = sc.textFile('./data/y_test_small.txt').zipWithIndex().map(lambda x:(x[1],x[0]))
    mytest = sc.textFile('.predictions.txt').zipWithIndex().map(lambda x:(x[1],x[0]))
    joined = ytest.join(mytest)

    
    matched = joined.filter(lambda (x,(y1,y2)):y1==y2).count()
    unmatched = joined.filter(lambda (x,(y1,y2)):y1!=y2).count()

    print "matched"
    print matched

    print "unmatched"
    print unmatched
    
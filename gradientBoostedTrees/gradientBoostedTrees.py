from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel
from pyspark.mllib.util import MLUtils
from pyspark.mllib.linalg import Vectors
from pyspark.mllib.regression import LabeledPoint
from pyspark.sql import SparkSession


#-------------------------------------------------------------------------------
# Initialize Spark
#-------------------------------------------------------------------------------
if __name__ == '__main__':


#-------------------------------------------------------------------------------
# Initialize Spark
#-------------------------------------------------------------------------------
    #initialize spark session
    spark = SparkSession\
            .builder\
            .appName("Test")\
            .getOrCreate()
    sc = spark.sparkContext

#-------------------------------------------------------------------------------
# Read the training data and build the model
#-------------------------------------------------------------------------------
    #reading the train dataframes
    trainingDF = spark.read.load("../data/train_small.parquet")     
    
    #convert every row to LabeledPoint
    transformedTrainingRDD = (trainingDF.rdd
                             .map(lambda row: LabeledPoint(row.label,row.features)))
    
    #Save the RDD in LibSVM format, as Naive Bayes reads in the same format
    MLUtils.saveAsLibSVMFile(transformedTrainingRDD,"trainingLibsvmfile")
    trainingData = MLUtils.loadLibSVMFile(sc, "trainingLibsvmfile/*")
    print "trainingLibsvmfile created!!"

    # Train a GradientBoostedTrees model.
    #  Notes: (a) Empty categoricalFeaturesInfo indicates all features are continuous.
    #         (b) Use more iterations in practice.
    model = GradientBoostedTrees.trainClassifier(trainingData,categoricalFeaturesInfo={}, numIterations=50)
    print "model built!!"

#-------------------------------------------------------------------------------
# Read the testing data and predict
#-------------------------------------------------------------------------------
    #reading the test dataframes
    testingDF = spark.read.load("../data/test_small.parquet")     
    
    #convert every row to LabeledPoint
    transformedTestRDD = (testingDF.rdd
                             .map(lambda row: LabeledPoint(row.label,row.features)))
    
    # Save the RDD in LibSVM format, as Naive Bayes reads in the same format
    # Remove libsvmfile if exists
    #if os.path.isdir("./testingLibsvmfile"):
    #    sh.rmtree("./testingLibsvmfile")
    
    MLUtils.saveAsLibSVMFile(transformedTestRDD,"testingLibsvmfile")
    testingData = MLUtils.loadLibSVMFile(sc, "testingLibsvmfile/*")
    print "testingLibsvmfile created!!"
    
   
    print "Predicting...."
    # Evaluate model on test instances and compute test error
    predictions = model.predict(testingData.map(lambda x: x.features))
    labelsAndPredictions = testingData.map(lambda lp: lp.label).zip(predictions)
    testIncorrect = labelsAndPredictions.filter(lambda (v, p): v != p).count()
    testCorrect = labelsAndPredictions.filter(lambda (v, p): v == p).count()
    print('Total Count: '+str(testingData.count()))
    print('Correct count = ' + str(testCorrect))
    print('Incorrect Count: '+str(testIncorrect))
    print('Learned classification GBT model:')
    print(model.toDebugString())



 
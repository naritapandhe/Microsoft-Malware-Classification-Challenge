from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel
from pyspark.mllib.util import MLUtils
from pyspark.mllib.linalg import Vectors
from pyspark.mllib.regression import LabeledPoint
from pyspark.sql import SparkSession
from tempfile import NamedTemporaryFile
from fileinput import input
from pyspark.mllib.util import MLUtils



if __name__ == '__main__':

    #initialize spark session
    spark = SparkSession\
            .builder\
            .appName("Test")\
            .getOrCreate()
    sc = spark.sparkContext

    #reading the train dataframes
    trainingDF = spark.read.load("../data/train_small.parquet")     
    
    #convert every row to LabeledPoint
    transformedTrainingRDD = (trainingDF.rdd
                             .map(lambda row: LabeledPoint(row.label,row.features)))
    
    #Save the RDD in LibSVM format, as Naive Bayes reads in the same format
    MLUtils.saveAsLibSVMFile(transformedTrainingRDD.coalesce(1),"libsvmfile")
    data = MLUtils.loadLibSVMFile(sc, "libsvmfile/part-00000")
    
    # Split data approximately into training (60%) and test (40%)
    training, test = data.randomSplit([0.6, 0.4])

    # Train a naive Bayes model.
    model = NaiveBayes.train(training, 1.0)

    # Make prediction and test accuracy.
    predictionAndLabel = test.map(lambda p: (model.predict(p.features), p.label))
    accuracy = 1.0 * predictionAndLabel.filter(lambda (x, v): x == v).count() / test.count()
    print('Accuracy after splitting training into training/testing: 60/40')
    print('model accuracy {}'.format(accuracy))


 
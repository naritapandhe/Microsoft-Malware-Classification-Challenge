from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel
from pyspark.mllib.util import MLUtils
from pyspark.mllib.linalg import Vectors
from pyspark.mllib.regression import LabeledPoint
from pyspark.sql import SparkSession
from tempfile import NamedTemporaryFile
from fileinput import input
from pyspark.mllib.util import MLUtils
import os
import shutil as sh


if __name__ == '__main__':

    #initialize spark session
    spark = SparkSession\
            .builder\
            .appName("Test")\
            .config('spark.sql.warehouse.dir', 'file:///C:/')\
            .getOrCreate()
    sc = spark.sparkContext
    sc.setLogLevel("ERROR")

    #reading the train dataframes
    trainingDF = spark.read.load("../data/train_small.parquet")     
    
    #convert every row to LabeledPoint
    transformedTrainingRDD = (trainingDF.rdd
                             .map(lambda row: LabeledPoint(row.label,row.features)))
    
    # Save the RDD in LibSVM format, as Naive Bayes reads in the same format
    # Remove libsvmfile if exists
    if os.path.isdir("./libsvmfile"):
        sh.rmtree("./libsvmfile")
    MLUtils.saveAsLibSVMFile(transformedTrainingRDD.coalesce(1),"libsvmfile")
    data = MLUtils.loadLibSVMFile(sc, "libsvmfile/part-00000")
    
    # Split data approximately into training (60%) and test (40%)
    training, test = data.randomSplit([0.6, 0.4])

    # Train a naive Bayes model.
    model = NaiveBayes.train(training, 1.0)

    # Make prediction and test accuracy.
    predictionAndLabel = test.map(lambda p: (model.predict(p.features), p.label))
    accuracy = 1.0 * predictionAndLabel.filter(lambda (x, v): x == v).count() / test.count()
    print('Accuracy after splitting training into training/testing: 60/40')
    print('model accuracy {}'.format(accuracy))

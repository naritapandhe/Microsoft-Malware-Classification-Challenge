from pyspark.sql import SparkSession
from pyspark.mllib.linalg import SparseVector, VectorUDT, Vectors
from pyspark.sql.types import *
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

if __name__ == '__main__':

#-------------------------------------------------------------------------------
# Initialize Spark
#-------------------------------------------------------------------------------
    #initialize spark session
    spark = SparkSession\
            .builder\
            .appName("Test")\
            .getOrCreate()
    sc = spark.sparkContext

#-------------------------------------------------------------------------------
# Read the training data and build the model
#-------------------------------------------------------------------------------
    #load data
    train = spark.read.load("./data1/train_small.parquet")
    print "training parquet read!!"

    
    # Train a RandomForest model.
    #  Empty categoricalFeaturesInfo indicates all features are continuous.
    #  Note: Use larger numTrees in practice.
    #  Setting featureSubsetStrategy="auto" lets the algorithm choose.
    rf = RandomForest(numClasses=10, categoricalFeaturesInfo={},
                         numTrees=200, featureSubsetStrategy="auto",
                         impurity='gini', maxDepth=8, maxBins=32)

    model = rf.fit(train)
    print "Model built!!"

#-------------------------------------------------------------------------------
# Read the testing data and predict
#-------------------------------------------------------------------------------
    #load data
    test = spark.read.load("./data/test_small.parquet")
    print "testing parquet read!!"

    result = model.transform(test)

    #get accuracy
    predictionAndLabels = result.select("prediction", "label")
    evaluator = MulticlassClassificationEvaluator(metricName="accuracy")
    print "Accuracy: " + str(evaluator.evaluate(predictionAndLabels))

    
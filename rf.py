from pyspark.mllib.tree import RandomForest, RandomForestModel
from pyspark.mllib.util import MLUtils
from pyspark.mllib.linalg import Vectors
from pyspark.mllib.regression import LabeledPoint
from pyspark.sql import SparkSession
import os
import shutil as sh


if __name__ == '__main__':

#-------------------------------------------------------------------------------
# Initialize Spark
#-------------------------------------------------------------------------------
    #initialize spark session
    spark = SparkSession\
            .builder\
            .appName("Test")\
            .getOrCreate()
    sc = spark.sparkContext

#-------------------------------------------------------------------------------
# Read the training data and build the model
#-------------------------------------------------------------------------------

    training = MLUtils.loadLibSVMFile(sc, "./ec2Output/libsvms/trainingLibsvmfile/*")
    print "trainingLibsvmfile read!!"

    
    # Train a RandomForest model.
    #  Empty categoricalFeaturesInfo indicates all features are continuous.
    #  Note: Use larger numTrees in practice.
    #  Setting featureSubsetStrategy="auto" lets the algorithm choose.
    model = RandomForest.trainClassifier(training, numClasses=10, categoricalFeaturesInfo={},
                                     numTrees=200, featureSubsetStrategy="auto",
                                     impurity='gini', maxDepth=8, maxBins=32)
    print "Model built!!"

#-------------------------------------------------------------------------------
# Read the testing data and predict
#-------------------------------------------------------------------------------
    testingData = MLUtils.loadLibSVMFile(sc, "./ec2Output/libsvms/testingLibsvmfile/*")
    print "testingLibsvmfile read!!"

    # Evaluate model on test instances and compute test error
    print "Predicting...."
    predictions = model.predict(testingData.map(lambda x: x.features))
    labelsAndPredictions = testingData.map(lambda lp: lp.label).zip(predictions)
    print labelsAndPredictions.take(1)
    print "After Predicting...."

    testIncorrect = labelsAndPredictions.filter(lambda (v, p): v != p).count()
    testCorrect = labelsAndPredictions.filter(lambda (v, p): v == p).count()
    print('Total Count: '+str(testingData.count()))
    print('Correct Count: '+str(testCorrect))
    print('Incorrect Count: '+str(testIncorrect))
    print('Learned classification forest model:')
    #print(model.toDebugString())
    